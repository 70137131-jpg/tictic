{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J4efdGHpBFdQ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from functools import lru_cache\n",
        "\n",
        "\n",
        "class Game:\n",
        "    \"\"\" The game class. New instance created for each new game. \"\"\"\n",
        "    def __init__(self, agent, teacher=None):\n",
        "        self.agent = agent\n",
        "        self.teacher = teacher\n",
        "        # initialize the game board\n",
        "        self.board = [['-', '-', '-'], ['-', '-', '-'], ['-', '-', '-']]\n",
        "\n",
        "    def playerMove(self):\n",
        "        \"\"\"\n",
        "        Querry player for a move and update the board accordingly.\n",
        "        \"\"\"\n",
        "        if self.teacher is not None:\n",
        "            action = self.teacher.makeMove(self.board)\n",
        "            self.board[action[0]][action[1]] = 'X'\n",
        "        else:\n",
        "            printBoard(self.board)\n",
        "            while True:\n",
        "                move = input(\"Your move! Please select a row and column from 0-2 \"\n",
        "                             \"in the format row,col: \")\n",
        "                print('\\n')\n",
        "                try:\n",
        "                    row, col = int(move[0]), int(move[2])\n",
        "                except ValueError:\n",
        "                    print(\"INVALID INPUT! Please use the correct format.\")\n",
        "                    continue\n",
        "                if row not in range(3) or col not in range(3) or not self.board[row][col] == '-':\n",
        "                    print(\"INVALID MOVE! Choose again.\")\n",
        "                    continue\n",
        "                self.board[row][col] = 'X'\n",
        "                break\n",
        "\n",
        "    def agentMove(self, action):\n",
        "        \"\"\"\n",
        "        Update board according to agent's move.\n",
        "        \"\"\"\n",
        "        self.board[action[0]][action[1]] = 'O'\n",
        "\n",
        "    def checkForWin(self, key):\n",
        "        \"\"\"\n",
        "        Check to see whether the player/agent with token 'key' has won.\n",
        "        Returns a boolean holding truth value.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        key : string\n",
        "            token of most recent player. Either 'O' or 'X'\n",
        "        \"\"\"\n",
        "        # check for player win on diagonals\n",
        "        a = [self.board[0][0], self.board[1][1], self.board[2][2]]\n",
        "        b = [self.board[0][2], self.board[1][1], self.board[2][0]]\n",
        "        if a.count(key) == 3 or b.count(key) == 3:\n",
        "            return True\n",
        "        # check for player win on rows/columns\n",
        "        for i in range(3):\n",
        "            col = [self.board[0][i], self.board[1][i], self.board[2][i]]\n",
        "            row = [self.board[i][0], self.board[i][1], self.board[i][2]]\n",
        "            if col.count(key) == 3 or row.count(key) == 3:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def checkForDraw(self):\n",
        "        \"\"\"\n",
        "        Check to see whether the game has ended in a draw. Returns a\n",
        "        boolean holding truth value.\n",
        "        \"\"\"\n",
        "        draw = True\n",
        "        for row in self.board:\n",
        "            for elt in row:\n",
        "                if elt == '-':\n",
        "                    draw = False\n",
        "        return draw\n",
        "\n",
        "    def checkForEnd(self, key):\n",
        "        \"\"\"\n",
        "        Checks if player/agent with token 'key' has ended the game. Returns -1\n",
        "        if the game is still going, 0 if it is a draw, and 1 if the player/agent\n",
        "        has won.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        key : string\n",
        "            token of most recent player. Either 'O' or 'X'\n",
        "        \"\"\"\n",
        "        if self.checkForWin(key):\n",
        "            if self.teacher is None:\n",
        "                printBoard(self.board)\n",
        "                if key == 'X':\n",
        "                    print(\"Player wins!\")\n",
        "                else:\n",
        "                    print(\"RL agent wins!\")\n",
        "            return 1\n",
        "        elif self.checkForDraw():\n",
        "            if self.teacher is None:\n",
        "                printBoard(self.board)\n",
        "                print(\"It's a draw!\")\n",
        "            return 0\n",
        "        return -1\n",
        "\n",
        "    def playGame(self, player_first):\n",
        "        \"\"\"\n",
        "        Begin the tic-tac-toe game loop.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        player_first : boolean\n",
        "            Whether or not the player will move first. If False, the\n",
        "            agent goes first.\n",
        "\n",
        "        \"\"\"\n",
        "        # Initialize the agent's state and action\n",
        "        if player_first:\n",
        "            self.playerMove()\n",
        "        prev_state = getStateKey(self.board)\n",
        "        prev_action = self.agent.get_action(prev_state)\n",
        "\n",
        "        # iterate until game is over\n",
        "        while True:\n",
        "            # execute oldAction, observe reward and state\n",
        "            self.agentMove(prev_action)\n",
        "            check = self.checkForEnd('O')\n",
        "            if not check == -1:\n",
        "                # game is over. +1 reward if win, 0 if draw\n",
        "                reward = check\n",
        "                break\n",
        "            self.playerMove()\n",
        "            check = self.checkForEnd('X')\n",
        "            if not check == -1:\n",
        "                # game is over. -1 reward if lose, 0 if draw\n",
        "                reward = -1*check\n",
        "                break\n",
        "            else:\n",
        "                # game continues. 0 reward\n",
        "                reward = 0\n",
        "            new_state = getStateKey(self.board)\n",
        "\n",
        "            # determine new action (epsilon-greedy)\n",
        "            new_action = self.agent.get_action(new_state)\n",
        "            # update Q-values\n",
        "            self.agent.update(prev_state, new_state, prev_action, new_action, reward)\n",
        "            # reset \"previous\" values\n",
        "            prev_state = new_state\n",
        "            prev_action = new_action\n",
        "            # append reward\n",
        "\n",
        "        # Game over. Perform final update\n",
        "        self.agent.update(prev_state, None, prev_action, None, reward)\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"\n",
        "        Function to determine who moves first, and subsequently, start the game.\n",
        "        If a teacher is employed, first mover is selected at random.\n",
        "        If a human is playing, the human is asked whether he/she would\n",
        "        like to move fist.\n",
        "        \"\"\"\n",
        "        if self.teacher is not None:\n",
        "            # During teaching, chose who goes first randomly with equal probability\n",
        "            if random.random() < 0.5:\n",
        "                self.playGame(player_first=False)\n",
        "            else:\n",
        "                self.playGame(player_first=True)\n",
        "        else:\n",
        "            while True:\n",
        "                response = input(\"Would you like to go first? [y/n]: \")\n",
        "                print('')\n",
        "                if response == 'n' or response == 'no':\n",
        "                    self.playGame(player_first=False)\n",
        "                    break\n",
        "                elif response == 'y' or response == 'yes':\n",
        "                    self.playGame(player_first=True)\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Invalid input. Please enter 'y' or 'n'.\")\n",
        "\n",
        "def printBoard(board):\n",
        "    \"\"\"\n",
        "    Prints the game board as text output to the terminal.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    board : list of lists\n",
        "        the current game board\n",
        "    \"\"\"\n",
        "    print('    0   1   2\\n')\n",
        "    for i, row in enumerate(board):\n",
        "        print('%i   ' % i, end='')\n",
        "        for elt in row:\n",
        "            print('%s   ' % elt, end='')\n",
        "        print('\\n')\n",
        "\n",
        "def getStateKey(board):\n",
        "    \"\"\"\n",
        "    Converts 2D list representing the board state into a string key\n",
        "    for that state. Keys are used for Q-value hashing.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    board : list of lists\n",
        "        the current game board\n",
        "    \"\"\"\n",
        "    key = ''\n",
        "    for row in board:\n",
        "        for elt in row:\n",
        "            key += elt\n",
        "    return key\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---------- Minimax baseline with transposition cache ----------\n",
        "\n",
        "def _flatten(board):\n",
        "    return ''.join(board[i][j] for i in range(3) for j in range(3))\n",
        "\n",
        "\n",
        "def _legal_moves(board):\n",
        "    moves = []\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            if board[i][j] == '-':\n",
        "                moves.append((i, j))\n",
        "    return moves\n",
        "\n",
        "\n",
        "def _winner(board):\n",
        "    # returns 'X', 'O', 'D' for draw, or None if ongoing\n",
        "    lines = [\n",
        "        # rows\n",
        "        [(0, 0), (0, 1), (0, 2)],\n",
        "        [(1, 0), (1, 1), (1, 2)],\n",
        "        [(2, 0), (2, 1), (2, 2)],\n",
        "        # cols\n",
        "        [(0, 0), (1, 0), (2, 0)],\n",
        "        [(0, 1), (1, 1), (2, 1)],\n",
        "        [(0, 2), (1, 2), (2, 2)],\n",
        "        # diagonals\n",
        "        [(0, 0), (1, 1), (2, 2)],\n",
        "        [(0, 2), (1, 1), (2, 0)],\n",
        "    ]\n",
        "    for line in lines:\n",
        "        a, b, c = line\n",
        "        v1, v2, v3 = board[a[0]][a[1]], board[b[0]][b[1]], board[c[0]][c[1]]\n",
        "        if v1 != '-' and v1 == v2 == v3:\n",
        "            return v1\n",
        "    if any(board[i][j] == '-' for i in range(3) for j in range(3)):\n",
        "        return None\n",
        "    return 'D'\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=None)\n",
        "def _minimax_cached(flat_board, player):\n",
        "    # player: 'X' or 'O' — returns (score, best_move)\n",
        "    board = [[flat_board[r * 3 + c] for c in range(3)] for r in range(3)]\n",
        "    term = _winner(board)\n",
        "    if term == 'X':\n",
        "        return 1, None\n",
        "    if term == 'O':\n",
        "        return -1, None\n",
        "    if term == 'D':\n",
        "        return 0, None\n",
        "\n",
        "    moves = _legal_moves(board)\n",
        "    if player == 'X':\n",
        "        best_score = -2\n",
        "        best_mv = None\n",
        "        for (i, j) in moves:\n",
        "            board[i][j] = 'X'\n",
        "            sc, _ = _minimax_cached(_flatten(board), 'O')\n",
        "            board[i][j] = '-'\n",
        "            if sc > best_score:\n",
        "                best_score, best_mv = sc, (i, j)\n",
        "                if best_score == 1:\n",
        "                    break\n",
        "        return best_score, best_mv\n",
        "    else:\n",
        "        best_score = 2\n",
        "        best_mv = None\n",
        "        for (i, j) in moves:\n",
        "            board[i][j] = 'O'\n",
        "            sc, _ = _minimax_cached(_flatten(board), 'X')\n",
        "            board[i][j] = '-'\n",
        "            if sc < best_score:\n",
        "                best_score, best_mv = sc, (i, j)\n",
        "                if best_score == -1:\n",
        "                    break\n",
        "        return best_score, best_mv\n",
        "\n",
        "\n",
        "def best_move_minimax(board, key='X'):\n",
        "    \"\"\"Return optimal move (i, j) for given key using cached minimax.\"\"\"\n",
        "    _, mv = _minimax_cached(_flatten(board), key)\n",
        "    # fallback to first legal if somehow None\n",
        "    return mv if mv is not None else (_legal_moves(board)[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OAWOk1PEBMs1"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "import os\n",
        "import pickle\n",
        "import collections\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "class Learner(ABC):\n",
        "    \"\"\"\n",
        "    Parent class for Q-learning and SARSA agents.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha : float\n",
        "        learning rate\n",
        "    gamma : float\n",
        "        temporal discounting rate\n",
        "    eps : float\n",
        "        probability of random action vs. greedy action\n",
        "    eps_decay : float\n",
        "        epsilon decay rate. Larger value = more decay\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha, gamma, eps, eps_decay=0.):\n",
        "        # Agent parameters\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.eps = eps\n",
        "        self.eps_decay = eps_decay\n",
        "        # Possible actions correspond to the set of all x,y coordinate pairs\n",
        "        self.actions = []\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                self.actions.append((i,j))\n",
        "        # Initialize Q values to 0 for all state-action pairs.\n",
        "        # Access value for action a, state s via Q[a][s]\n",
        "        self.Q = {}\n",
        "        for action in self.actions:\n",
        "            self.Q[action] = collections.defaultdict(int)\n",
        "        # Keep a list of reward received at each episode\n",
        "        self.rewards = []\n",
        "\n",
        "    def get_action(self, s):\n",
        "        \"\"\"\n",
        "        Select an action given the current game state.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        s : string\n",
        "            state\n",
        "        \"\"\"\n",
        "        # Only consider the allowed actions (empty board spaces)\n",
        "        possible_actions = [a for a in self.actions if s[a[0]*3 + a[1]] == '-']\n",
        "        if random.random() < self.eps:\n",
        "            # Random choose.\n",
        "            action = possible_actions[random.randint(0,len(possible_actions)-1)]\n",
        "        else:\n",
        "            # Greedy choose.\n",
        "            values = np.array([self.Q[a][s] for a in possible_actions])\n",
        "            # Find location of max\n",
        "            ix_max = np.where(values == np.max(values))[0]\n",
        "            if len(ix_max) > 1:\n",
        "                # If multiple actions were max, then sample from them\n",
        "                ix_select = np.random.choice(ix_max, 1)[0]\n",
        "            else:\n",
        "                # If unique max action, select that one\n",
        "                ix_select = ix_max[0]\n",
        "            action = possible_actions[ix_select]\n",
        "\n",
        "        # update epsilon; geometric decay\n",
        "        self.eps *= (1.-self.eps_decay)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\" Pickle the agent object instance to save the agent's state. \"\"\"\n",
        "        if os.path.isfile(path):\n",
        "            os.remove(path)\n",
        "        f = open(path, 'wb')\n",
        "        pickle.dump(self, f)\n",
        "        f.close()\n",
        "\n",
        "    @abstractmethod\n",
        "    def update(self, s, s_, a, a_, r):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Qlearner(Learner):\n",
        "    \"\"\"\n",
        "    A class to implement the Q-learning agent.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha, gamma, eps, eps_decay=0.):\n",
        "        super().__init__(alpha, gamma, eps, eps_decay)\n",
        "\n",
        "    def update(self, s, s_, a, a_, r):\n",
        "        \"\"\"\n",
        "        Perform the Q-Learning update of Q values.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        s : string\n",
        "            previous state\n",
        "        s_ : string\n",
        "            new state\n",
        "        a : (i,j) tuple\n",
        "            previous action\n",
        "        a_ : (i,j) tuple\n",
        "            new action. NOT used by Q-learner!\n",
        "        r : int\n",
        "            reward received after executing action \"a\" in state \"s\"\n",
        "        \"\"\"\n",
        "        # Update Q(s,a)\n",
        "        if s_ is not None:\n",
        "            # hold list of Q values for all a_,s_ pairs. We will access the max later\n",
        "            possible_actions = [action for action in self.actions if s_[action[0]*3 + action[1]] == '-']\n",
        "            Q_options = [self.Q[action][s_] for action in possible_actions]\n",
        "            # update\n",
        "            self.Q[a][s] += self.alpha*(r + self.gamma*max(Q_options) - self.Q[a][s])\n",
        "        else:\n",
        "            # terminal state update\n",
        "            self.Q[a][s] += self.alpha*(r - self.Q[a][s])\n",
        "\n",
        "        # add r to rewards list\n",
        "        self.rewards.append(r)\n",
        "\n",
        "\n",
        "class SARSAlearner(Learner):\n",
        "    \"\"\"\n",
        "    A class to implement the SARSA agent.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha, gamma, eps, eps_decay=0.):\n",
        "        super().__init__(alpha, gamma, eps, eps_decay)\n",
        "\n",
        "    def update(self, s, s_, a, a_, r):\n",
        "        \"\"\"\n",
        "        Perform the SARSA update of Q values.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        s : string\n",
        "            previous state\n",
        "        s_ : string\n",
        "            new state\n",
        "        a : (i,j) tuple\n",
        "            previous action\n",
        "        a_ : (i,j) tuple\n",
        "            new action\n",
        "        r : int\n",
        "            reward received after executing action \"a\" in state \"s\"\n",
        "        \"\"\"\n",
        "        # Update Q(s,a)\n",
        "        if s_ is not None:\n",
        "            self.Q[a][s] += self.alpha*(r + self.gamma*self.Q[a_][s_] - self.Q[a][s])\n",
        "        else:\n",
        "            # terminal state update\n",
        "            self.Q[a][s] += self.alpha*(r - self.Q[a][s])\n",
        "\n",
        "        # add r to rewards list\n",
        "        self.rewards.append(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "87CwNToaBS4b"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# from .game import best_move_minimax\n",
        "\n",
        "class Teacher:\n",
        "    \"\"\"\n",
        "    A class to implement a teacher that knows the optimal playing strategy.\n",
        "    Teacher returns the best move at any time given the current state of the game.\n",
        "    Note: things are a bit more hard-coded here, as this was not the main focus of\n",
        "    the exercise so I did not spend as much time on design/style. Everything works\n",
        "    properly when tested.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    level : float\n",
        "        teacher ability level. This is a value between 0-1 that indicates the\n",
        "        probability of making the optimal move at any given time.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, level=0.9, strategy='rules'):\n",
        "        \"\"\"\n",
        "        Ability level determines the probability that the teacher will follow\n",
        "        the optimal strategy as opposed to choosing a random available move.\n",
        "        \"\"\"\n",
        "        self.ability_level = level\n",
        "        # strategy: 'rules' (existing heuristic) or 'minimax' (optimal)\n",
        "        self.strategy = strategy\n",
        "\n",
        "    def win(self, board, key='X'):\n",
        "        \"\"\" If we have two in a row and the 3rd is available, take it. \"\"\"\n",
        "        # Check for diagonal wins\n",
        "        a = [board[0][0], board[1][1], board[2][2]]\n",
        "        b = [board[0][2], board[1][1], board[2][0]]\n",
        "        if a.count('-') == 1 and a.count(key) == 2:\n",
        "            ind = a.index('-')\n",
        "            return ind, ind\n",
        "        elif b.count('-') == 1 and b.count(key) == 2:\n",
        "            ind = b.index('-')\n",
        "            if ind == 0:\n",
        "                return 0, 2\n",
        "            elif ind == 1:\n",
        "                return 1, 1\n",
        "            else:\n",
        "                return 2, 0\n",
        "        # Now check for 2 in a row/column + empty 3rd\n",
        "        for i in range(3):\n",
        "            c = [board[0][i], board[1][i], board[2][i]]\n",
        "            d = [board[i][0], board[i][1], board[i][2]]\n",
        "            if c.count('-') == 1 and c.count(key) == 2:\n",
        "                ind = c.index('-')\n",
        "                return ind, i\n",
        "            elif d.count('-') == 1 and d.count(key) == 2:\n",
        "                ind = d.index('-')\n",
        "                return i, ind\n",
        "        return None\n",
        "\n",
        "    def blockWin(self, board):\n",
        "        \"\"\" Block the opponent if she has a win available. \"\"\"\n",
        "        return self.win(board, key='O')\n",
        "\n",
        "    def fork(self, board):\n",
        "        \"\"\" Create a fork opportunity such that we have 2 threats to win. \"\"\"\n",
        "        # Check all adjacent side middles\n",
        "        if board[1][0] == 'X' and board[0][1] == 'X':\n",
        "            if board[0][0] == '-' and board[2][0] == '-' and board[0][2] == '-':\n",
        "                return 0, 0\n",
        "            elif board[1][1] == '-' and board[2][1] == '-' and board[1][2] == '-':\n",
        "                return 1, 1\n",
        "        elif board[1][0] == 'X' and board[2][1] == 'X':\n",
        "            if board[2][0] == '-' and board[0][0] == '-' and board[2][2] == '-':\n",
        "                return 2, 0\n",
        "            elif board[1][1] == '-' and board[0][1] == '-' and board[1][2] == '-':\n",
        "                return 1, 1\n",
        "        elif board[2][1] == 'X' and board[1][2] == 'X':\n",
        "            if board[2][2] == '-' and board[2][0] == '-' and board[0][2] == '-':\n",
        "                return 2, 2\n",
        "            elif board[1][1] == '-' and board[1][0] == '-' and board[0][1] == '-':\n",
        "                return 1, 1\n",
        "        elif board[1][2] == 'X' and board[0][1] == 'X':\n",
        "            if board[0][2] == '-' and board[0][0] == '-' and board[2][2] == '-':\n",
        "                return 0, 2\n",
        "            elif board[1][1] == '-' and board[1][0] == '-' and board[2][1] == '-':\n",
        "                return 1, 1\n",
        "        # Check all cross corners\n",
        "        elif board[0][0] == 'X' and board[2][2] == 'X':\n",
        "            if board[1][0] == '-' and board[2][1] == '-' and board[2][0] == '-':\n",
        "                return 2, 0\n",
        "            elif board[0][1] == '-' and board[1][2] == '-' and board[0][2] == '-':\n",
        "                return 0, 2\n",
        "        elif board[2][0] == 'X' and board[0][2] == 'X':\n",
        "            if board[2][1] == '-' and board[1][2] == '-' and board[2][2] == '-':\n",
        "                return 2, 2\n",
        "            elif board[1][0] == '-' and board[0][1] == '-' and board[0][0] == '-':\n",
        "                return 0, 0\n",
        "        return None\n",
        "\n",
        "    def blockFork(self, board):\n",
        "        \"\"\" Block the opponents fork if she has one available. \"\"\"\n",
        "        corners = [board[0][0], board[2][0], board[0][2], board[2][2]]\n",
        "        # Check all adjacent side middles\n",
        "        if board[1][0] == 'O' and board[0][1] == 'O':\n",
        "            if board[0][0] == '-' and board[2][0] == '-' and board[0][2] == '-':\n",
        "                return 0, 0\n",
        "            elif board[1][1] == '-' and board[2][1] == '-' and board[1][2] == '-':\n",
        "                return 1, 1\n",
        "        elif board[1][0] == 'O' and board[2][1] == 'O':\n",
        "            if board[2][0] == '-' and board[0][0] == '-' and board[2][2] == '-':\n",
        "                return 2, 0\n",
        "            elif board[1][1] == '-' and board[0][1] == '-' and board[1][2] == '-':\n",
        "                return 1, 1\n",
        "        elif board[2][1] == 'O' and board[1][2] == 'O':\n",
        "            if board[2][2] == '-' and board[2][0] == '-' and board[0][2] == '-':\n",
        "                return 2, 2\n",
        "            elif board[1][1] == '-' and board[1][0] == '-' and board[0][1] == '-':\n",
        "                return 1, 1\n",
        "        elif board[1][2] == 'O' and board[0][1] == 'O':\n",
        "            if board[0][2] == '-' and board[0][0] == '-' and board[2][2] == '-':\n",
        "                return 0, 2\n",
        "            elif board[1][1] == '-' and board[1][0] == '-' and board[2][1] == '-':\n",
        "                return 1, 1\n",
        "        # Check all cross corners (first check for double fork opp using the corners array)\n",
        "        elif corners.count('-') == 1 and corners.count('O') == 2:\n",
        "            return 1, 2\n",
        "        elif board[0][0] == 'O' and board[2][2] == 'O':\n",
        "            if board[1][0] == '-' and board[2][1] == '-' and board[2][0] == '-':\n",
        "                return 2, 0\n",
        "            elif board[0][1] == '-' and board[1][2] == '-' and board[0][2] == '-':\n",
        "                return 0, 2\n",
        "        elif board[2][0] == 'O' and board[0][2] == 'O':\n",
        "            if board[2][1] == '-' and board[1][2] == '-' and board[2][2] == '-':\n",
        "                return 2, 2\n",
        "            elif board[1][0] == '-' and board[0][1] == '-' and board[0][0] == '-':\n",
        "                return 0, 0\n",
        "        return None\n",
        "\n",
        "    def center(self, board):\n",
        "        \"\"\" Pick the center if it is available. \"\"\"\n",
        "        if board[1][1] == '-':\n",
        "            return 1, 1\n",
        "        return None\n",
        "\n",
        "    def corner(self, board):\n",
        "        \"\"\" Pick a corner move. \"\"\"\n",
        "        # Pick opposite corner of opponent if available\n",
        "        if board[0][0] == 'O' and board[2][2] == '-':\n",
        "            return 2, 2\n",
        "        elif board[2][0] == 'O' and board[0][2] == '-':\n",
        "            return 0, 2\n",
        "        elif board[0][2] == 'O' and board[2][0] == '-':\n",
        "            return 2, 0\n",
        "        elif board[2][2] == 'O' and board[0][0] == '-':\n",
        "            return 0, 0\n",
        "        # Pick any corner if no opposites are available\n",
        "        elif board[0][0] == '-':\n",
        "            return 0, 0\n",
        "        elif board[2][0] == '-':\n",
        "            return 2, 0\n",
        "        elif board[0][2] == '-':\n",
        "            return 0, 2\n",
        "        elif board[2][2] == '-':\n",
        "            return 2, 2\n",
        "        return None\n",
        "\n",
        "    def sideEmpty(self, board):\n",
        "        \"\"\" Pick an empty side. \"\"\"\n",
        "        if board[1][0] == '-':\n",
        "            return 1, 0\n",
        "        elif board[2][1] == '-':\n",
        "            return 2, 1\n",
        "        elif board[1][2] == '-':\n",
        "            return 1, 2\n",
        "        elif board[0][1] == '-':\n",
        "            return 0, 1\n",
        "        return None\n",
        "\n",
        "    def randomMove(self, board):\n",
        "        \"\"\" Chose a random move from the available options. \"\"\"\n",
        "        possibles = []\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                if board[i][j] == '-':\n",
        "                    possibles += [(i, j)]\n",
        "        return possibles[random.randint(0, len(possibles)-1)]\n",
        "\n",
        "    def makeMove(self, board):\n",
        "        \"\"\"\n",
        "        Trainer goes through a hierarchy of moves, making the best move that\n",
        "        is currently available each time. A touple is returned that represents\n",
        "        (row, col).\n",
        "        \"\"\"\n",
        "        # Chance to deviate from optimal to avoid determinism\n",
        "        if random.random() > self.ability_level:\n",
        "            return self.randomMove(board)\n",
        "\n",
        "        if self.strategy == 'minimax':\n",
        "            return best_move_minimax(board, key='X')\n",
        "\n",
        "        # Default heuristic strategy\n",
        "        a = self.win(board)\n",
        "        if a is not None:\n",
        "            return a\n",
        "        a = self.blockWin(board)\n",
        "        if a is not None:\n",
        "            return a\n",
        "        a = self.fork(board)\n",
        "        if a is not None:\n",
        "            return a\n",
        "        a = self.blockFork(board)\n",
        "        if a is not None:\n",
        "            return a\n",
        "        a = self.center(board)\n",
        "        if a is not None:\n",
        "            return a\n",
        "        a = self.corner(board)\n",
        "        if a is not None:\n",
        "            return a\n",
        "        a = self.sideEmpty(board)\n",
        "        if a is not None:\n",
        "            return a\n",
        "        return self.randomMove(board)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyXehf8oBTUj",
        "outputId": "5f1f25b8-43e1-46ab-a90a-001de515cee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Q-learning agent for 50000 episodes...\n",
            "Teacher ability level: 0.9\n",
            "Episode 10000/50000 | Time: 1.3s\n",
            "Episode 20000/50000 | Time: 2.2s\n",
            "Episode 30000/50000 | Time: 3.1s\n",
            "Episode 40000/50000 | Time: 4.1s\n",
            "Episode 50000/50000 | Time: 5.0s\n",
            "\n",
            "✅ Training complete in 5.0 seconds!\n",
            "Agent saved to: q_agent.pkl\n",
            "Total rewards: 10932\n",
            "Win rate (approx): 9.2%\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# from tictactoe.agent import Qlearner\n",
        "# from tictactoe.teacher import Teacher\n",
        "# from tictactoe.game import Game\n",
        "\n",
        "def train_agent(episodes=50000, teacher_ability=1.0):\n",
        "    \"\"\"Train a Q-learning agent.\"\"\"\n",
        "    print(f\"Training Q-learning agent for {episodes} episodes...\")\n",
        "    print(f\"Teacher (minimax) ability level: {teacher_ability}\")\n",
        "\n",
        "    agent = Qlearner(alpha=0.5, gamma=0.9, eps=0.1)\n",
        "    teacher = Teacher(level=teacher_ability, strategy='minimax')\n",
        "\n",
        "    start_time = time.time()\n",
        "    wins = draws = losses = 0\n",
        "\n",
        "    for i in range(episodes):\n",
        "        # Track terminal reward appended at the end of the game\n",
        "        prev_len = len(agent.rewards)\n",
        "        game = Game(agent, teacher=teacher)\n",
        "        game.start()\n",
        "        # Determine episode outcome from final appended reward (1 win, 0 draw, -1 loss)\n",
        "        if len(agent.rewards) > prev_len:\n",
        "            last_r = agent.rewards[-1]\n",
        "            if last_r > 0:\n",
        "                wins += 1\n",
        "            elif last_r == 0:\n",
        "                draws += 1\n",
        "            else:\n",
        "                losses += 1\n",
        "\n",
        "        # Progress updates\n",
        "        if (i + 1) % 10000 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(f\"Episode {i + 1}/{episodes} | Time: {elapsed:.1f}s | W/D/L: {wins}/{draws}/{losses}\")\n",
        "\n",
        "    # Saves trained agent\n",
        "    agent.save('q_agent.pkl')\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\n✅ Training complete in {total_time:.1f} seconds!\")\n",
        "    print(f\"Agent saved to: q_agent.pkl\")\n",
        "    print(f\"Total rewards: {sum(agent.rewards)}\")\n",
        "    print(f\"Win rate (approx): {(sum(1 for r in agent.rewards if r > 0) / len(agent.rewards)) * 100:.1f}%\")\n",
        "    # Episode-level outcomes (more accurate)\n",
        "    total = max(1, wins + draws + losses)\n",
        "    print(f\"Wins: {wins} ({wins/total*100:.1f}%)\")\n",
        "    print(f\"Draws: {draws} ({draws/total*100:.1f}%)\")\n",
        "    print(f\"Losses: {losses} ({losses/total*100:.1f}%)\")\n",
        "    # Episode-level outcomes (more accurate)\n",
        "    total = max(1, wins + draws + losses)\n",
        "    print(f\"Wins: {wins} ({wins/total*100:.1f}%)\")\n",
        "    print(f\"Draws: {draws} ({draws/total*100:.1f}%)\")\n",
        "    print(f\"Losses: {losses} ({losses/total*100:.1f}%)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_agent(episodes=50000, teacher_ability=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "arEkC4dKBoEc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "# from tictactoe.agent import Qlearner, SARSAlearner\n",
        "# from tictactoe.teacher import Teacher\n",
        "# from tictactoe.game import Game\n",
        "\n",
        "\n",
        "class GameLearning(object):\n",
        "    \"\"\"\n",
        "    A class that holds the state of the learning process. Learning\n",
        "    agents are created/loaded here, and a count is kept of the\n",
        "    games that have been played.\n",
        "    \"\"\"\n",
        "    def __init__(self, agent_type=\"q\", path=None, load=False, alpha=0.5, gamma=0.9, epsilon=0.1):\n",
        "\n",
        "        if path is None:\n",
        "             path = 'q_agent.pkl' if agent_type == 'q' else 'sarsa_agent.pkl'\n",
        "\n",
        "        if load:\n",
        "            # load an existing agent and continue training\n",
        "            if not os.path.isfile(path):\n",
        "                raise ValueError(f\"Cannot load agent: file does not exist at {path}.\")\n",
        "            with open(path, 'rb') as f:\n",
        "                agent = pickle.load(f)\n",
        "        else:\n",
        "            # check if agent state file already exists, and ask\n",
        "            # user whether to overwrite if so\n",
        "            if os.path.isfile(path):\n",
        "                print(f'An agent is already saved at {path}.')\n",
        "                while True:\n",
        "                    response = input(\"Are you sure you want to overwrite? [y/n]: \")\n",
        "                    if response.lower() in ['y', 'yes']:\n",
        "                        break\n",
        "                    elif response.lower() in ['n', 'no']:\n",
        "                        print(\"OK. Quitting.\")\n",
        "                        sys.exit(0)\n",
        "                    else:\n",
        "                        print(\"Invalid input. Please choose 'y' or 'n'.\")\n",
        "            if agent_type == \"q\":\n",
        "                agent = Qlearner(alpha,gamma,epsilon)\n",
        "            else:\n",
        "                agent = SARSAlearner(alpha,gamma,epsilon)\n",
        "\n",
        "        self.games_played = 0\n",
        "        self.path = path\n",
        "        self.agent = agent\n",
        "\n",
        "    def beginPlaying(self):\n",
        "        \"\"\" Loop through game iterations with a human player. \"\"\"\n",
        "        print(\"Welcome to Tic-Tac-Toe. You are 'X' and the computer is 'O'.\")\n",
        "\n",
        "        def play_again():\n",
        "            print(\"Games played: %i\" % self.games_played)\n",
        "            while True:\n",
        "                play = input(\"Do you want to play again? [y/n]: \")\n",
        "                if play == 'y' or play == 'yes':\n",
        "                    return True\n",
        "                elif play == 'n' or play == 'no':\n",
        "                    return False\n",
        "                else:\n",
        "                    print(\"Invalid input. Please choose 'y' or 'n'.\")\n",
        "\n",
        "        while True:\n",
        "            game = Game(self.agent)\n",
        "            game.start()\n",
        "            self.games_played += 1\n",
        "            self.agent.save(self.path)\n",
        "            if not play_again():\n",
        "                print(\"OK. Quitting.\")\n",
        "                break\n",
        "\n",
        "    def beginTeaching(self, episodes):\n",
        "        \"\"\" Loop through game iterations with a teaching agent. \"\"\"\n",
        "        teacher = Teacher()\n",
        "        # Train for alotted number of episodes\n",
        "        while self.games_played < episodes:\n",
        "            game = Game(self.agent, teacher=teacher)\n",
        "            game.start()\n",
        "            self.games_played += 1\n",
        "            # Monitor progress\n",
        "            if self.games_played % 1000 == 0:\n",
        "                print(\"Games played: %i\" % self.games_played)\n",
        "        # save final agent\n",
        "        self.agent.save(self.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LVUQU8AZBxRD"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "# from tictactoe.agent import Qlearner, SARSAlearner\n",
        "# from tictactoe.game import getStateKey, best_move_minimax\n",
        "# from tictactoe.teacher import Teacher\n",
        "\n",
        "\n",
        "def _legal_moves(board):\n",
        "    moves = []\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            if board[i][j] == '-':\n",
        "                moves.append((i, j))\n",
        "    return moves\n",
        "\n",
        "\n",
        "def _winner(board):\n",
        "    # returns 'X', 'O', 'D' for draw, or None if ongoing\n",
        "    lines = [\n",
        "        # rows\n",
        "        [(0, 0), (0, 1), (0, 2)],\n",
        "        [(1, 0), (1, 1), (1, 2)],\n",
        "        [(2, 0), (2, 1), (2, 2)],\n",
        "        # cols\n",
        "        [(0, 0), (1, 0), (2, 0)],\n",
        "        [(0, 1), (1, 1), (2, 1)],\n",
        "        [(0, 2), (1, 2), (2, 2)],\n",
        "        # diagonals\n",
        "        [(0, 0), (1, 1), (2, 2)],\n",
        "        [(0, 2), (1, 1), (2, 0)],\n",
        "    ]\n",
        "    for line in lines:\n",
        "        a, b, c = line\n",
        "        v1, v2, v3 = board[a[0]][a[1]], board[b[0]][b[1]], board[c[0]][c[1]]\n",
        "        if v1 != '-' and v1 == v2 == v3:\n",
        "            return v1\n",
        "    if any(board[i][j] == '-' for i in range(3) for j in range(3)):\n",
        "        return None\n",
        "    return 'D'\n",
        "\n",
        "\n",
        "def _agent_greedy_move(agent, board) -> Tuple[int, int]:\n",
        "    \"\"\"Return the agent's greedy (eps=0) move without learning side-effects.\"\"\"\n",
        "    state = getStateKey(board)\n",
        "    possible = _legal_moves(board)\n",
        "    # Choose action that maximizes Q(a, s). Break ties randomly.\n",
        "    values = [agent.Q[a][state] for a in possible]\n",
        "    max_val = max(values)\n",
        "    best_idxs = [i for i, v in enumerate(values) if v == max_val]\n",
        "    choice_idx = random.choice(best_idxs)\n",
        "    return possible[choice_idx]\n",
        "\n",
        "\n",
        "def evaluate_agent(\n",
        "    agent_path: str = 'q_agent.pkl',\n",
        "    agent_type: str = 'q',\n",
        "    games: int = 1000,\n",
        "    opponent: str = 'minimax',  # 'minimax' | 'random' | 'teacher'\n",
        "    teacher_ability: float = 0.9,\n",
        "    verbose: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate a trained agent by playing games without learning updates.\n",
        "\n",
        "    - Agent plays as 'O'. Opponent plays as 'X' and moves first.\n",
        "    - Greedy policy is used (no exploration, no Q updates).\n",
        "\n",
        "    Returns (wins, draws, losses).\n",
        "    \"\"\"\n",
        "    # Load agent\n",
        "    if not os.path.isfile(agent_path):\n",
        "        raise FileNotFoundError(f\"Agent not found at {agent_path}\")\n",
        "    with open(agent_path, 'rb') as f:\n",
        "        agent = pickle.load(f)\n",
        "\n",
        "    # Build opponent policy\n",
        "    if opponent == 'random':\n",
        "        def opp_move(board):\n",
        "            return random.choice(_legal_moves(board))\n",
        "    elif opponent == 'teacher':\n",
        "        teacher = Teacher(level=teacher_ability)\n",
        "        def opp_move(board):\n",
        "            return teacher.makeMove(board)\n",
        "    else:  # minimax (default)\n",
        "        def opp_move(board):\n",
        "            return best_move_minimax(board, key='X')\n",
        "\n",
        "    wins = draws = losses = 0\n",
        "\n",
        "    for g in range(games):\n",
        "        board = [['-', '-', '-'], ['-', '-', '-'], ['-', '-', '-']]\n",
        "        turn = 'X'  # opponent starts as X\n",
        "        if verbose:\n",
        "            print(f\"\\nGame {g+1}\")\n",
        "        while True:\n",
        "            if turn == 'X':\n",
        "                i, j = opp_move(board)\n",
        "                board[i][j] = 'X'\n",
        "                term = _winner(board)\n",
        "                if term is not None:\n",
        "                    if term == 'X':\n",
        "                        losses += 1\n",
        "                    elif term == 'O':\n",
        "                        wins += 1\n",
        "                    else:\n",
        "                        draws += 1\n",
        "                    break\n",
        "                turn = 'O'\n",
        "            else:  # agent 'O'\n",
        "                i, j = _agent_greedy_move(agent, board)\n",
        "                board[i][j] = 'O'\n",
        "                term = _winner(board)\n",
        "                if term is not None:\n",
        "                    if term == 'X':\n",
        "                        losses += 1\n",
        "                    elif term == 'O':\n",
        "                        wins += 1\n",
        "                    else:\n",
        "                        draws += 1\n",
        "                    break\n",
        "                turn = 'X'\n",
        "\n",
        "    return wins, draws, losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3c6ba83",
        "outputId": "b93662bf-eb0d-4391-989b-4ada9e6123af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation results:\n",
            "Games:   1000\n",
            "Wins:    0 (0.0%)\n",
            "Draws:   0 (0.0%)\n",
            "Losses:  1000 (100.0%)\n"
          ]
        }
      ],
      "source": [
        "# --- Agent Evaluation Settings ---\n",
        "\n",
        "# Path to the trained agent pickle file\n",
        "agent_path = 'q_agent.pkl'\n",
        "\n",
        "# Agent type (for display purposes)\n",
        "agent_type = 'q'\n",
        "\n",
        "# Number of evaluation games to play\n",
        "evaluation_games = 1000\n",
        "\n",
        "# Opponent policy: 'minimax' | 'random' | 'teacher'\n",
        "opponent_policy = 'minimax'\n",
        "\n",
        "# Teacher ability level (if opponent is 'teacher')\n",
        "eval_teacher_ability = 0.9\n",
        "\n",
        "# Set to True to print per-game progress\n",
        "verbose_evaluation = False\n",
        "\n",
        "# --- End Settings ---\n",
        "\n",
        "# Run the evaluation\n",
        "wins, draws, losses = evaluate_agent(\n",
        "    agent_path=agent_path,\n",
        "    agent_type=agent_type,\n",
        "    games=evaluation_games,\n",
        "    opponent=opponent_policy,\n",
        "    teacher_ability=eval_teacher_ability,\n",
        "    verbose=verbose_evaluation,\n",
        ")\n",
        "\n",
        "total = max(1, wins + draws + losses)\n",
        "print('\\nEvaluation results:')\n",
        "print(f'Games:   {total}')\n",
        "print(f'Wins:    {wins} ({wins/total*100:.1f}%)')\n",
        "print(f'Draws:   {draws} ({draws/total*100:.1f}%)')\n",
        "print(f'Losses:  {losses} ({losses/total*100:.1f}%)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42bf7ab8",
        "outputId": "14e64fbe-e6ef-4e7a-ff1a-3739b16ff966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An agent is already saved at q_agent.pkl.\n",
            "Games played: 1000\n",
            "Games played: 2000\n",
            "Games played: 3000\n",
            "Games played: 4000\n",
            "Games played: 5000\n",
            "Games played: 6000\n",
            "Games played: 7000\n",
            "Games played: 8000\n",
            "Games played: 9000\n",
            "Games played: 10000\n",
            "Games played: 11000\n",
            "Games played: 12000\n",
            "Games played: 13000\n",
            "Games played: 14000\n",
            "Games played: 15000\n",
            "Games played: 16000\n",
            "Games played: 17000\n",
            "Games played: 18000\n",
            "Games played: 19000\n",
            "Games played: 20000\n",
            "Games played: 21000\n",
            "Games played: 22000\n",
            "Games played: 23000\n",
            "Games played: 24000\n",
            "Games played: 25000\n",
            "Games played: 26000\n",
            "Games played: 27000\n",
            "Games played: 28000\n",
            "Games played: 29000\n",
            "Games played: 30000\n",
            "Games played: 31000\n",
            "Games played: 32000\n",
            "Games played: 33000\n",
            "Games played: 34000\n",
            "Games played: 35000\n",
            "Games played: 36000\n",
            "Games played: 37000\n",
            "Games played: 38000\n",
            "Games played: 39000\n",
            "Games played: 40000\n",
            "Games played: 41000\n",
            "Games played: 42000\n",
            "Games played: 43000\n",
            "Games played: 44000\n",
            "Games played: 45000\n",
            "Games played: 46000\n",
            "Games played: 47000\n",
            "Games played: 48000\n",
            "Games played: 49000\n",
            "Games played: 50000\n"
          ]
        }
      ],
      "source": [
        "# --- Game Learning Settings ---\n",
        "\n",
        "# Choose the agent type: 'q' for Q-learning, 's' for Sarsa-learning\n",
        "agent_type = 'q'\n",
        "\n",
        "# Specify the path to save/load the agent pickle file.\n",
        "# If None, defaults to 'q_agent.pkl' or 'sarsa_agent.pkl' based on agent_type.\n",
        "agent_path = 'q_agent.pkl'\n",
        "\n",
        "# Set to True to load a trained agent from the specified path, False to start fresh.\n",
        "load_agent = False\n",
        "\n",
        "# If training with a teacher, specify the number of episodes.\n",
        "# If None, the agent will play against a human player.\n",
        "teacher_episodes = 50000\n",
        "\n",
        "# --- End Settings ---\n",
        "\n",
        "\n",
        "# Initialize and start the GameLearning instance\n",
        "gl = GameLearning(agent_type=agent_type,\n",
        "                  path=agent_path,\n",
        "                  load=load_agent)\n",
        "\n",
        "if teacher_episodes is not None:\n",
        "    gl.beginTeaching(teacher_episodes)\n",
        "else:\n",
        "    gl.beginPlaying()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "A5p0_ehgCJ1K",
        "outputId": "2d06308f-1546-4c25-f6f2-245c522e19e6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "\n",
        "def plot_agent_reward(rewards):\n",
        "    \"\"\" Function to plot agent's accumulated reward vs. iteration \"\"\"\n",
        "    plt.plot(np.cumsum(rewards))\n",
        "    plt.title('Agent Cumulative Reward vs. Iteration')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- Plotting Settings ---\n",
        "\n",
        "# Path to the trained agent pickle file\n",
        "agent_plot_path = 'q_agent.pkl'\n",
        "\n",
        "# --- End Settings ---\n",
        "\n",
        "\n",
        "if not os.path.isfile(agent_plot_path):\n",
        "    print(f\"Cannot load agent: file does not exist at {agent_plot_path}. Quitting.\")\n",
        "else:\n",
        "    with open(agent_plot_path, 'rb') as f:\n",
        "        agent = pickle.load(f)\n",
        "\n",
        "    plot_agent_reward(agent.rewards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Flask Application Setup\n",
        "\n",
        "Now that the model is trained and saved as `q_agent.pkl`, you can run the Flask application.\n",
        "\n",
        "## Steps to run the Flask app:\n",
        "\n",
        "1. **Install Flask requirements** (if not already installed):\n",
        "   ```bash\n",
        "   pip install flask numpy\n",
        "   ```\n",
        "\n",
        "2. **Run the Flask application**:\n",
        "   ```bash\n",
        "   python app.py\n",
        "   ```\n",
        "\n",
        "3. **Open in browser**:\n",
        "   Navigate to http://127.0.0.1:5000\n",
        "\n",
        "The Flask app will automatically load the trained `q_agent.pkl` model and use it to play Tic-Tac-Toe.\n",
        "\n",
        "## API Endpoints:\n",
        "- `GET /` - Web UI to play against the agent\n",
        "- `POST /api/move` - Get agent's move for a given board state\n",
        "- `POST /api/evaluate` - Evaluate agent performance over multiple games"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify that the trained model exists and is ready for Flask app\n",
        "import os\n",
        "\n",
        "model_path = 'q_agent.pkl'\n",
        "\n",
        "if os.path.isfile(model_path):\n",
        "    print(f\"✅ Trained model found at: {model_path}\")\n",
        "    print(f\"📊 Model size: {os.path.getsize(model_path) / 1024:.2f} KB\")\n",
        "    print(\"\\n🎮 You can now run the Flask app with: python app.py\")\n",
        "    \n",
        "    # Load and inspect the model\n",
        "    with open(model_path, 'rb') as f:\n",
        "        agent = pickle.load(f)\n",
        "    \n",
        "    print(f\"\\n📈 Model Statistics:\")\n",
        "    print(f\"   - Total Q-values learned: {sum(len(agent.Q[action]) for action in agent.actions)}\")\n",
        "    print(f\"   - Training episodes: {len(agent.rewards)}\")\n",
        "    print(f\"   - Final epsilon (exploration rate): {agent.eps:.4f}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"❌ Trained model NOT found at: {model_path}\")\n",
        "    print(\"\\n⚠️  Please run the training cells above first:\")\n",
        "    print(\"   - Run the 'Game Learning Settings' cell to train the agent\")\n",
        "    print(\"   - Or run train_agent() function to create the model\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
